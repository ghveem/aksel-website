name: Backup dataset to gcp
on:
  workflow_dispatch:
  schedule:
    # 12.00 every 3 days
    - cron: "0 0 */3 * *"
jobs:
  execute:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
        with:
          fetch-depth: 0 # Required to retrieve git history
      - uses: actions/setup-node@v1
        with:
          node-version: 14
      - name: Node-modules cache
        uses: actions/cache@v2
        id: node-cache
        with:
          path: "**/node_modules"
          key: ${{ runner.os }}-modules-${{ hashFiles('**/yarn.lock') }}
      - name: Install deps
        if: steps.node-cache.outputs.cache-hit != 'true'
        run: yarn install
      - name: log dir
        run: pwd
      - name: Export dataset
        run: SANITY_TOKEN=${{secrets.SANITY_DATASET_EDITOR_TOKEN}} yarn sanity:backup
      - name: Upload GCP bucket
        uses: "google-github-actions/auth@v0"
        with:
          credentials_json: "${{ secrets.gcp_credentials_prod }}"
      - uses: "google-github-actions/upload-cloud-storage@v0"
        with:
          path: ./sanity
          destination: "aksel-website-prod/backups"
          glob: "**/backup-*.tar.gz"
